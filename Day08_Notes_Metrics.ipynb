{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall22Code/blob/main/Day08_Notes_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example code from CS 167 on September 22, 2022\n"
      ],
      "metadata": {
        "id": "OBeIpkdkchRS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iASFhd-li8CJ"
      },
      "source": [
        "# Metrics and Testing\n",
        "Let's use the iris dataset and see how accurate our kNN model is."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3OQ3GMQpQp97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5MUhMRvhpip"
      },
      "source": [
        "data = pandas.read_csv('/content/drive/MyDrive/CS167Fall22/Datasets/irisData.csv') #change this line to point to your data\n",
        "#shuffle the data - \"sampling\" the full set in random order\n",
        "shuffled_data = data.sample(frac=1, random_state=41)\n",
        "#use the first 20 rows in the shuffled set as testing data #train with the rest\n",
        "test_data = shuffled_data.iloc[0:20]\n",
        "train_data = shuffled_data.iloc[20:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at the testing_data\n",
        "print(\"testing data shape:\", test_data.shape)\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "AxZwAEGeJ6wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at the training_data\n",
        "print(\"training data shape:\", train_data.shape)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "-9ve9NcHKO95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFWmCEvKhFyu"
      },
      "source": [
        "def classify_kNN(new_example,train_data,k):\n",
        "    # outputs the most commonly-occuring (mode) species of the closeset k training examples \n",
        "    # designed to work on the iris data set\n",
        "    train_data_copy = train_data.copy() #use a copy of the training set just so we don't mess up the original\n",
        "    train_data_copy['distance_to_new'] = numpy.sqrt(\n",
        "        (new_example['petal length']-train_data_copy['petal length'])**2\n",
        "        +(new_example['sepal length']-train_data_copy['sepal length'])**2\n",
        "        +(new_example['petal width']-train_data_copy['petal width'])**2\n",
        "        +(new_example['sepal width']-train_data_copy['sepal width'])**2)\n",
        "    sorted_data = train_data_copy.sort_values(['distance_to_new'])\n",
        "    #mode() will return most common thing in the closest k examples in the sorted dataframe; iloc will get the actual string of the species\n",
        "    prediction = sorted_data.iloc[0:k]['species'].mode().iloc[0] \n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmkVTsxPhW5f"
      },
      "source": [
        "def accuracy(actual,predicted):\n",
        "    # INPUT: \n",
        "    #   actual: a list of values\n",
        "    #   predicted: a list of value\n",
        "    #   (we assume that number of elements in actual and predicted match)\n",
        "    # OUTPUT: \n",
        "    #   the percentage in which predicted & actual values match\n",
        "    num_correct = 0\n",
        "    for i in range(len(actual)):\n",
        "      if actual.iloc[i] == predicted.iloc[i]:\n",
        "        num_correct +=1\n",
        "    frac_correct = num_correct/len(actual)\n",
        "    return frac_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #1\n",
        "fill in the code where you see ####"
      ],
      "metadata": {
        "id": "Hx1bICAzNIQC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj5WQfWlha-K"
      },
      "source": [
        "def classify_all_kNN(test_data, train_data, k):\n",
        "    # INPUT:\n",
        "    #   test_data: a dataframe of the testing data set\n",
        "    #   train_data: a dataframe of the training data set\n",
        "    #   k: an integer\n",
        "    # OUTPUT:\n",
        "    #   a pandas.Series of the predicted results\n",
        "    # for each item in the test_data list, apply the classify_kNN function (also passing the train_data and k)\n",
        "    # return a pandas.Series of the predicted results\n",
        "    results = []\n",
        "    for i in range(len(test_data)):\n",
        "      #### get a prediction from kNN for test_data at position i\n",
        "      #### add that prediction to the results list\n",
        "    return pandas.Series(results)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml7mBuNYhfXn"
      },
      "source": [
        "# get a list of predictions using 5-NN\n",
        "predictions5NN = classify_all_kNN(test_data,train_data,5)\n",
        "\n",
        "# print out the ACTUAL vs. PREDICTIONS for our testing data\n",
        "print('ACTUAL\\t\\tPREDICTIONS')\n",
        "for i in range(len(test_data)):\n",
        "    print(test_data['species'].iloc[i], \"---\", predictions5NN.iloc[i] )\n",
        "\n",
        "# print out the accuracy...\n",
        "acc = accuracy(test_data['species'],predictions5NN)\n",
        "print(\"accuracy:\", acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF6mj584hiA4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#reload the data\n",
        "data = pandas.read_csv('/content/drive/MyDrive/CS167Fall22/Datasets/irisData.csv')\n",
        "\n",
        "shuffled_data = data.sample(frac=1, random_state = 41)\n",
        "\n",
        "# create test and training data sets\n",
        "test_data = shuffled_data.iloc[0:20]\n",
        "train_data = shuffled_data.iloc[20:]\n",
        "\n",
        "# explore different values of k\n",
        "k_vals = [1,3,5]\n",
        "kNN_accuracies = []\n",
        "\n",
        "for k in k_vals:\n",
        "    predictions = classify_all_kNN(test_data,train_data,k)\n",
        "    current_accuracy = accuracy(test_data['species'],predictions)\n",
        "    kNN_accuracies.append(current_accuracy)\n",
        "\n",
        "\n",
        "plt.suptitle('Iris Data k-NN Experiment',fontsize=18)\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(k_vals,kNN_accuracies,'ro-',label='k-NN')\n",
        "plt.legend(loc='lower left', shadow=True)\n",
        "plt.axis([0,10,0,1])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #2:\n",
        "To Do:\n",
        "- add more points: add multiple values of k to the graph \n",
        "- explain the phenomenon that you observe"
      ],
      "metadata": {
        "id": "RnKyVbbSQ9_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #3:\n",
        "To do:\n",
        "- What happens if you change the testing size? 25? 30?\n",
        "- What happens if you use a different random number seed (other than 41)?\n",
        "- Explain what is happening (and why).\n"
      ],
      "metadata": {
        "id": "K_WTs-xmUxXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #4 Penguins!!\n"
      ],
      "metadata": {
        "id": "Kf0tuXZPQPtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def penguin_classify_kNN(new_example,train_data,k):\n",
        "    # outputs the most commonly-occuring (mode) species of the closeset k training examples \n",
        "    # designed to work on the iris data set\n",
        "    train_data_copy = train_data.copy() #use a copy of the training set just so we don't mess up the original\n",
        "    train_data_copy['distance_to_new'] = numpy.sqrt(\n",
        "        (new_example['bill_length_mm']-train_data_copy['bill_length_mm'])**2\n",
        "        +(new_example['bill_depth_mm']-train_data_copy['bill_depth_mm'])**2\n",
        "        +(new_example['flipper_length_mm']-train_data_copy['flipper_length_mm'])**2\n",
        "        +(new_example['body_mass_g']-train_data_copy['body_mass_g'])**2)\n",
        "    sorted_data = train_data_copy.sort_values(['distance_to_new'])\n",
        "    #mode() will return most common thing in the closest k examples in the sorted dataframe; iloc will get the actual string of the species\n",
        "    prediction = sorted_data.iloc[0:k]['species'].mode().iloc[0] \n",
        "    return prediction"
      ],
      "metadata": {
        "id": "OzPXzbYWVSB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def penguin_classify_all_kNN(test_data, train_data, k):\n",
        "    # INPUT:\n",
        "    #   test_data: a dataframe of the testing data set\n",
        "    #   train_data: a dataframe of the training data set\n",
        "    #   k: an integer\n",
        "    # OUTPUT:\n",
        "    #   a pandas.Series of the predicted results\n",
        "    # for each item in the test_data list, apply the classify_kNN function (also passing the train_data and k)\n",
        "    # return a pandas.Series of the predicted results\n",
        "    results = []\n",
        "    for i in range(len(test_data)):\n",
        "      #### get a prediction from kNN for test_data at position i\n",
        "      prediction = penguin_classify_kNN(test_data.iloc[i],train_data,k)\n",
        "      #### add that prediction to the results list\n",
        "      results.append(prediction)\n",
        "    return pandas.Series(results)\n"
      ],
      "metadata": {
        "id": "vEBXGdwydnNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#load the data\n",
        "data = pandas.read_csv('/content/drive/MyDrive/CS167Fall22/Datasets/penguins.csv')\n",
        "\n",
        "#clean the data -- I'm okay just getting rid of any rows with any null values...\n",
        "data.dropna(inplace = True)\n",
        "data.head()\n"
      ],
      "metadata": {
        "id": "efZtUioEkBUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}